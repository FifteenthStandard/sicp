<!DOCTYPE html>
<html lang="en-AU">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>SICP | Structure and Interpretation of Computer Programs</title>
  <link rel="icon" href="favicon.png">
  <link rel="stylesheet" href="css/layout.css">
  <link rel="stylesheet" href="css/style.css">
</head>

<body>
<header>
  <hgroup>
    <h1>Structure and Interpretation of Computer Programs</h1>
    <p>Second edition</p>
  </hgroup>
  <address>
    <p>
      Harold Abelson and Gerald Jay Sussman with Julie Sussman <br>
      foreword by Alan J. Perlis
    </p>
    <p>
      The MIT Press <br>
      Cambridge, Massachusetts&emsp;London, England
    </p>
    <p>
      McGraw-Hill Book Company <br>
      New York&emsp;St. Louis&emsp;San Francisco&emsp;Montreal&emsp;Toronto 
    </p>
  </address>
</header>

<main>
<section id="s0">
<section id="s0.1">
  <h3><a href="#s0.1">Foreward</a></h3>
  <p>
    Educators, generals, dieticians, psychologists, and parents program.
    Armies, students, and some societies are programmed. An assault on large
    problems employs a succession of programs, most of which spring into
    existence en route. These programs are rife with issues that appear to be
    particular to the problem at hand. To appreciate programming as an
    intellectual activity in its own right you must turn to computer
    programming; you must read and write computer programs—many of them. It
    doesn’t matter much what the programs are about or what applications they
    serve. What does matter is how well they perform and how smoothly they fit
    with other programs in the creation of still greater programs. The
    programmer must seek both perfection of part and adequacy of collection. In
    this book the use of “program” is focused on the creation, execution, and
    study of programs written in a dialect of Lisp for execution on a digital
    computer. Using Lisp we restrict or limit not what we may program, but only
    the notation for our program descriptions.
  </p>
  <p>
    Our traffic with the subject matter of this book involves us with three
    foci of phenomena: the human mind, collections of computer programs, and
    the computer. Every computer program is a model, hatched in the mind, of a
    real or mental process. These processes, arising from human experience and
    thought, are huge in number, intricate in detail, and at any time only
    partially understood. They are modeled to our permanent satisfaction rarely
    by our computer programs. Thus even though our programs are carefully
    handcrafted discrete collections of symbols, mosaics of interlocking
    functions, they continually evolve: we change them as our perception of the
    model deepens, enlarges, generalizes until the model ultimately attains a
    metastable place within still another model with which we struggle. The
    source of the exhilaration associated with computer programming is the
    continual unfolding within the mind and on the computer of mechanisms
    expressed as programs and the explosion of perception they generate. If art
    interprets our dreams, the computer executes them in the guise of programs!
  </p>
  <p>
    For all its power, the computer is a harsh taskmaster. Its programs must be
    correct, and what we wish to say must be said accurately in every detail.
    As in every other symbolic activity, we become convinced of program truth
    through argument. Lisp itself can be assigned a semantics (another model,
    by the way), and if a program’s function can be specified, say, in the
    predicate calculus, the proof methods of logic can be used to make an
    acceptable correctness argument. Unfortunately, as programs get large and
    complicated, as they almost always do, the adequacy, consistency, and
    correctness of the specifications themselves become open to doubt, so that
    complete formal arguments of correctness seldom accompany large programs.
    Since large programs grow from small ones, it is crucial that we develop an
    arsenal of standard program structures of whose correctness we have become
    sure—we call them idioms—and learn to combine them into larger structures
    using organizational techniques of proven value. These techniques are
    treated at length in this book, and understanding them is essential to
    participation in the Promethean enterprise called programming. More than
    anything else, the uncovering and mastery of powerful organizational
    techniques accelerates our ability to create large, significant programs.
    Conversely, since writing large programs is very taxing, we are stimulated
    to invent new methods of reducing the mass of function and detail to be
    fitted into large programs.
  </p>
  <p>
    Unlike programs, computers must obey the laws of physics. If they wish to
    perform rapidly—a few nanoseconds per state change—they must transmit
    electrons only small distances (at most 1 1/2 feet). The heat generated by
    the huge number of devices so concentrated in space has to be removed. An
    exquisite engineering art has been developed balancing between multiplicity
    of function and density of devices. In any event, hardware always operates
    at a level more primitive than that at which we care to program. The
    processes that transform our Lisp programs to “machine” programs are
    themselves abstract models which we program. Their study and creation give
    a great deal of insight into the organizational programs associated with
    programming arbitrary models. Of course the computer itself can be so
    modeled. Think of it: the behavior of the smallest physical switching
    element is modeled by quantum mechanics described by differential equations
    whose detailed behavior is captured by numerical approximations represented
    in computer programs executing on computers composed of ...!
  </p>
  <p>
    It is not merely a matter of tactical convenience to separately identify
    the three foci. Even though, as they say, it’s all in the head, this
    logical separation induces an acceleration of symbolic traffic between
    these foci whose richness, vitality, and potential is exceeded in human
    experience only by the evolution of life itself. At best, relationships
    between the foci are metastable. The computers are never large enough or
    fast enough. Each breakthrough in hardware technology leads to more massive
    programming enterprises, new organizational principles, and an enrichment
    of abstract models. Every reader should ask himself periodically “Toward
    what end, toward what end?”—but do not ask it too often lest you pass up
    the fun of programming for the constipation of bittersweet philosophy.
  </p>
  <p>
    Among the programs we write, some (but never enough) perform a precise
    mathematical function such as sorting or finding the maximum of a sequence
    of numbers, determining primality, or finding the square root. We call such
    programs algorithms, and a great deal is known of their optimal behavior,
    particularly with respect to the two important parameters of execution time
    and data storage requirements. A programmer should acquire good algorithms
    and idioms. Even though some programs resist precise specifications, it is
    the responsibility of the programmer to estimate, and always to attempt to
    improve, their performance.
  </p>
  <p>
    Lisp is a survivor, having been in use for about a quarter of a century.
    Among the active programming languages only Fortran has had a longer life.
    Both languages have supported the programming needs of important areas of
    application, Fortran for scientific and engineering computation and Lisp
    for artificial intelligence. These two areas continue to be important, and
    their programmers are so devoted to these two languages that Lisp and
    Fortran may well continue in active use for at least another
    quarter-century.
  </p>
  <p>
    Lisp changes. The Scheme dialect used in this text has evolved from the
    original Lisp and differs from the latter in several important ways,
    including static scoping for variable binding and permitting functions to
    yield functions as values. In its semantic structure Scheme is as closely
    akin to Algol 60 as to early Lisps. Algol 60, never to be an active
    language again, lives on in the genes of Scheme and Pascal. It would be
    difficult to find two languages that are the communicating coin of two more
    different cultures than those gathered around these two languages. Pascal
    is for building pyramids—imposing, breathtaking, static structures built by
    armies pushing heavy blocks into place. Lisp is for building
    organisms—imposing, breathtaking, dynamic structures built by squads
    fitting fluctuating myriads of simpler organisms into place. The organizing
    principles used are the same in both cases, except for one extraordinarily
    important difference: The discretionary exportable functionality entrusted
    to the individual Lisp programmer is more than an order of magnitude
    greater than that to be found within Pascal enterprises. Lisp programs
    inflate libraries with functions whose utility transcends the application
    that produced them. The list, Lisp’s native data structure, is largely
    responsible for such growth of utility. The simple structure and natural
    applicability of lists are reflected in functions that are amazingly
    nonidiosyncratic. In Pascal the plethora of declarable data structures
    induces a specialization within functions that inhibits and penalizes
    casual cooperation. It is better to have 100 functions operate on one data
    structure than to have 10 functions operate on 10 data structures. As a
    result the pyramid must stand unchanged for a millennium; the organism must
    evolve or perish.
  </p>
  <p>
    To illustrate this difference, compare the treatment of material and
    exercises within this book with that in any first-course text using Pascal.
    Do not labor under the illusion that this is a text digestible at MIT only,
    peculiar to the breed found there. It is precisely what a serious book on
    programming Lisp must be, no matter who the student is or where it is used.
  </p>
  <p>
    Note that this is a text about programming, unlike most Lisp books, which
    are used as a preparation for work in artificial intelligence. After all,
    the critical programming concerns of software engineering and artificial
    intelligence tend to coalesce as the systems under investigation become
    larger. This explains why there is such growing interest in Lisp outside of
    artificial intelligence.
  </p>
  <p>
    As one would expect from its goals, artificial intelligence research
    generates many significant programming problems. In other programming
    cultures this spate of problems spawns new languages. Indeed, in any very
    large programming task a useful organizing principle is to control and
    isolate traffic within the task modules via the invention of language.
    These languages tend to become less primitive as one approaches the
    boundaries of the system where we humans interact most often. As a result,
    such systems contain complex language-processing functions replicated many
    times. Lisp has such a simple syntax and semantics that parsing can be
    treated as an elementary task. Thus parsing technology plays almost no role
    in Lisp programs, and the construction of language processors is rarely an
    impediment to the rate of growth and change of large Lisp systems. Finally,
    it is this very simplicity of syntax and semantics that is responsible for
    the burden and freedom borne by all Lisp programmers. No Lisp program of
    any size beyond a few lines can be written without being saturated with
    discretionary functions. Invent and fit; have fits and reinvent! We toast
    the Lisp programmer who pens his thoughts within nests of parentheses.
  </p>
  <address>
    Alan J. Perlis <br>
    New Haven, Connecticut
  </address>
</section>

<section id="s0.2">
  <h3><a href="#s0.2">Preface to the Second Edition</a></h3>
  <blockquote>
    <p>
      Is it possible that software is not like anything else, that it is meant
      to be discarded: that the whole point is to always see it as a soap
      bubble?
    </p>
    <address>
      Alan J. Perlis
    </address>
  </blockquote>
  <p>
    The material in this book has been the basis of MIT’s entry-level computer
    science subject since 1980. We had been teaching this material for four
    years when the first edition was published, and twelve more years have
    elapsed until the appearance of this second edition. We are pleased that
    our work has been widely adopted and incorporated into other texts. We have
    seen our students take the ideas and programs in this book and build them
    in as the core of new computer systems and languages. In literal
    realization of an ancient Talmudic pun, our students have become our
    builders. We are lucky to have such capable students and such accomplished
    builders.
  </p>
  <p>
    In preparing this edition, we have incorporated hundreds of clarifications
    suggested by our own teaching experience and the comments of colleagues at
    MIT and elsewhere. We have redesigned most of the major programming systems
    in the book, including the generic-arithmetic system, the interpreters, the
    register-machine simulator, and the compiler; and we have rewritten all the
    program examples to ensure that any Scheme implementation conforming to the
    IEEE Scheme standard (IEEE 1990) will be able to run the code.
  </p>
  <p>
    This edition emphasizes several new themes. The most important of these is
    the central role played by different approaches to dealing with time in
    computational models: objects with state, concurrent programming,
    functional programming, lazy evaluation, and nondeterministic programming.
    We have included new sections on concurrency and nondeterminism, and we
    have tried to integrate this theme throughout the book.
  </p>
  <p>
    The first edition of the book closely followed the syllabus of our MIT
    one-semester subject. With all the new material in the second edition, it
    will not be possible to cover everything in a single semester, so the
    instructor will have to pick and choose. In our own teaching, we sometimes
    skip the section on logic programming (section <a href="#s4.4">4.4</a>), we
    have students use the register-machine simulator but we do not cover its
    implementation (section <a href="#s5.2">5.2</a>), and we give only a
    cursory overview of the compiler (section <a href="#s5.5">5.5</a>). Even
    so, this is still an intense course. Some instructors may wish to cover
    only the first three or four chapters, leaving the other material for
    subsequent courses.
  </p>
  <p>
    The World-Wide-Web site <a href="https://mitpress.mit.edu/sicp"
    >mitpress.mit.edu/sicp</a> provides support for users of this book. This
    includes programs from the book, sample programming assignments,
    supplementary materials, and downloadable implementations of the Scheme
    dialect of Lisp.
  </p>
</section>

<section id="s0.3">
  <h3><a href="#s0.3">Preface to the First Edition</a></h3>
  <blockquote>
    <p>
      A computer is like a violin. You can imagine a novice trying first a
      phonograph and then a violin. The latter, he says, sounds terrible. That
      is the argument we have heard from our humanists and most of our computer
      scientists. Computer programs are good, they say, for particular
      purposes, but they aren’t flexible. Neither is a violin, or a typewriter,
      until you learn how to use it.
    </p>
    <address>
      Marvin Minsky, “Why Programming Is a Good Medium for Expressing
      Poorly-Understood and Sloppily-Formulated Ideas”
    </address>
  </blockquote>
  <p>
    “The Structure and Interpretation of Computer Programs” is the entry-level
    subject in computer science at the Massachusetts Institute of Technology.
    It is required of all students at MIT who major in electrical engineering
    or in computer science, as one-fourth of the “common core curriculum,”
    which also includes two subjects on circuits and linear systems and a
    subject on the design of digital systems. We have been involved in the
    development of this subject since 1978, and we have taught this material in
    its present form since the fall of 1980 to between 600 and 700 students
    each year. Most of these students have had little or no prior formal
    training in computation, although many have played with computers a bit and
    a few have had extensive programming or hardware-design experience.
  </p>
  <p>
    Our design of this introductory computer-science subject reflects two major
    concerns. First, we want to establish the idea that a computer language is
    not just a way of getting a computer to perform operations but rather that
    it is a novel formal medium for expressing ideas about methodology. Thus,
    programs must be written for people to read, and only incidentally for
    machines to execute. Second, we believe that the essential material to be
    addressed by a subject at this level is not the syntax of particular
    programming-language constructs, nor clever algorithms for computing
    particular functions efficiently, nor even the mathematical analysis of
    algorithms and the foundations of computing, but rather the techniques used
    to control the intellectual complexity of large software systems.
  </p>
  <p>
    Our goal is that students who complete this subject should have a good feel
    for the elements of style and the aesthetics of programming. They should
    have command of the major techniques for controlling complexity in a large
    system. They should be capable of reading a 50-page-long program, if it is
    written in an exemplary style. They should know what not to read, and what
    they need not understand at any moment. They should feel secure about
    modifying a program, retaining the spirit and style of the original author.
  </p>
  <p>
    These skills are by no means unique to computer programming. The techniques
    we teach and draw upon are common to all of engineering design. We control
    complexity by building abstractions that hide details when appropriate. We
    control complexity by establishing conventional interfaces that enable us
    to construct systems by combining standard, well-understood pieces in a
    “mix and match” way. We control complexity by establishing new languages
    for describing a design, each of which emphasizes particular aspects of the
    design and deemphasizes others.
  </p>
  <p>
    Underlying our approach to this subject is our conviction that “computer
    science” is not a science and that its significance has little to do with
    computers. The computer revolution is a revolution in the way we think and
    in the way we express what we think. The essence of this change is the
    emergence of what might best be called procedural epistemology—the study of
    the structure of knowledge from an imperative point of view, as opposed to
    the more declarative point of view taken by classical mathematical
    subjects. Mathematics provides a framework for dealing precisely with
    notions of “what is.” Computation provides a framework for dealing
    precisely with notions of “how to.”
  </p>
  <p>
    In teaching our material we use a dialect of the programming language Lisp.
    We never formally teach the language, because we don’t have to. We just use
    it, and students pick it up in a few days. This is one great advantage of
    Lisp-like languages: They have very few ways of forming compound
    expressions, and almost no syntactic structure. All of the formal
    properties can be covered in an hour, like the rules of chess. After a
    short time we forget about syntactic details of the language (because there
    are none) and get on with the real issues—figuring out what we want to
    compute, how we will decompose problems into manageable parts, and how we
    will work on the parts. Another advantage of Lisp is that it supports (but
    does not enforce) more of the large-scale strategies for modular
    decomposition of programs than any other language we know. We can make
    procedural and data abstractions, we can use higher-order functions to
    capture common patterns of usage, we can model local state using assignment
    and data mutation, we can link parts of a program with streams and delayed
    evaluation, and we can easily implement embedded languages. All of this is
    embedded in an interactive environment with excellent support for
    incremental program design, construction, testing, and debugging. We thank
    all the generations of Lisp wizards, starting with John McCarthy, who have
    fashioned a fine tool of unprecedented power and elegance.
  </p>
  <p>
    Scheme, the dialect of Lisp that we use, is an attempt to bring together
    the power and elegance of Lisp and Algol. From Lisp we take the
    metalinguistic power that derives from the simple syntax, the uniform
    representation of programs as data objects, and the garbage-collected
    heap-allocated data. From Algol we take lexical scoping and block
    structure, which are gifts from the pioneers of programming-language design
    who were on the Algol committee. We wish to cite John Reynolds and Peter
    Landin for their insights into the relationship of Church’s lambda calculus
    to the structure of programming languages. We also recognize our debt to
     the mathematicians who scouted out this territory decades before computers
     appeared on the scene. These pioneers include Alonzo Church, Barkley
     Rosser, Stephen Kleene, and Haskell Curry.
  </p>
</section>

<section id="s0.4">
  <h3><a href="#s0.4">Acknowledgements</a></h3>
  <p>
    We would like to thank the many people who have helped us develop this book
    and this curriculum.
  </p>
  <p>
    Our subject is a clear intellectual descendant of “6.231,” a wonderful
    subject on programming linguistics and the lambda calculus taught at MIT in
    the late 1960s by Jack Wozencraft and Arthur Evans, Jr.
  </p>
  <p>
    We owe a great debt to Robert Fano, who reorganized MIT’s introductory
    curriculum in electrical engineering and computer science to emphasize the
    principles of engineering design. He led us in starting out on this
    enterprise and wrote the first set of subject notes from which this book
    evolved.
  </p>
  <p>
    Much of the style and aesthetics of programming that we try to teach were
    developed in conjunction with Guy Lewis Steele Jr., who collaborated with
    Gerald Jay Sussman in the initial development of the Scheme language. In
    addition, David Turner, Peter Henderson, Dan Friedman, David Wise, and Will
    Clinger have taught us many of the techniques of the functional programming
    community that appear in this book.
  </p>
  <p>
    Joel Moses taught us about structuring large systems. His experience with
    the Macsyma system for symbolic computation provided the insight that one
    should avoid complexities of control and concentrate on organizing the data
    to reflect the real structure of the world being modeled.
  </p>
  <p>
    Marvin Minsky and Seymour Papert formed many of our attitudes about
    programming and its place in our intellectual lives. To them we owe the
    understanding that computation provides a means of expression for exploring
    ideas that would otherwise be too complex to deal with precisely. They
    emphasize that a student’s ability to write and modify programs provides a
    powerful medium in which exploring becomes a natural activity.
  </p>
  <p>
    We also strongly agree with Alan Perlis that programming is lots of fun and
    we had better be careful to support the joy of programming. Part of this
    joy derives from observing great masters at work. We are fortunate to have
    been apprentice programmers at the feet of Bill Gosper and Richard
    Greenblatt.
  </p>
  <p>
    It is difficult to identify all the people who have contributed to the
    development of our curriculum. We thank all the lecturers, recitation
    instructors, and tutors who have worked with us over the past fifteen years
    and put in many extra hours on our subject, especially Bill Siebert, Albert
    Meyer, Joe Stoy, Randy Davis, Louis Braida, Eric Grimson, Rod Brooks, Lynn
    Stein, and Peter Szolovits. We would like to specially acknowledge the
    outstanding teaching contributions of Franklyn Turbak, now at Wellesley;
    his work in undergraduate instruction set a standard that we can all aspire
    to. We are grateful to Jerry Saltzer and Jim Miller for helping us grapple
    with the mysteries of concurrency, and to Peter Szolovits and David
    McAllester for their contributions to the exposition of nondeterministic
    evaluation in chapter 4.
  </p>
  <p>
    Many people have put in significant effort presenting this material at
    other universities. Some of the people we have worked closely with are
    Jacob Katzenelson at the Technion, Hardy Mayer at the University of
    California at Irvine, Joe Stoy at Oxford, Elisha Sacks at Purdue, and Jan
    Komorowski at the Norwegian University of Science and Technology. We are
    exceptionally proud of our colleagues who have received major teaching
    awards for their adaptations of this subject at other universities,
    including Kenneth Yip at Yale, Brian Harvey at the University of California
    at Berkeley, and Dan Huttenlocher at Cornell.
  </p>
  <p>
    Al Moyé arranged for us to teach this material to engineers at
    Hewlett-Packard, and for the production of videotapes of these lectures. We
    would like to thank the talented instructors—in particular Jim Miller, Bill
    Siebert, and Mike Eisenberg—who have designed continuing education courses
    incorporating these tapes and taught them at universities and industry all
    over the world.
  </p>
  <p>
    Many educators in other countries have put in significant work translating
    the first edition. Michel Briand, Pierre Chamard, and André Pic produced a
    French edition; Susanne Daniels-Herold produced a German edition; and Fumio
    Motoyoshi produced a Japanese edition. We do not know who produced the
    Chinese edition, but we consider it an honor to have been selected as the
    subject of an “unauthorized” translation.
  </p>
  <p>
    It is hard to enumerate all the people who have made technical
    contributions to the development of the Scheme systems we use for
    instructional purposes. In addition to Guy Steele, principal wizards have
    included Chris Hanson, Joe Bowbeer, Jim Miller, Guillermo Rozas, and
    Stephen Adams. Others who have put in significant time are Richard
    Stallman, Alan Bawden, Kent Pitman, Jon Taft, Neil Mayle, John Lamping,
    Gwyn Osnos, Tracy Larrabee, George Carrette, Soma Chaudhuri, Bill
    Chiarchiaro, Steven Kirsch, Leigh Klotz, Wayne Noss, Todd Cass, Patrick
    O’Donnell, Kevin Theobald, Daniel Weise, Kenneth Sinclair, Anthony
    Courtemanche, Henry M. Wu, Andrew Berlin, and Ruth Shyu.
  </p>
  <p>
    Beyond the MIT implementation, we would like to thank the many people who
    worked on the IEEE Scheme standard, including William Clinger and Jonathan
    Rees, who edited the R4RS, and Chris Haynes, David Bartley, Chris Hanson,
    and Jim Miller, who prepared the IEEE standard.
  </p>
  <p>
    Dan Friedman has been a long-time leader of the Scheme community. The
    community’s broader work goes beyond issues of language design to encompas
    significant educational innovations, such as the high-school curriculum
    based on EdScheme by Schemer’s Inc., and the wonderful books by Mike
    Eisenberg and by Brian Harvey and Matthew Wright.
  </p>
  <p>
    We appreciate the work of those who contributed to making this a real book,
    especially Terry Ehling, Larry Cohen, and Paul Bethge at the MIT Press.
    Ella Mazel found the wonderful cover image. For the second edition we are
    particularly grateful to Bernard and Ella Mazel for help with the book
    design, and to David Jones, TEX wizard extraordinaire. We also are indebted
    to those readers who made penetrating comments on the new draft: Jacob
    Katzenelson, Hardy Mayer, Jim Miller, and especially Brian Harvey, who did
    unto this book as Julie did unto his book Simply Scheme.
  </p>
  <p>
    Finally, we would like to acknowledge the support of the organizations that
    have encouraged this work over the years, including support from
    Hewlett-Packard, made possible by Ira Goldstein and Joel Birnbaum, and
    support from DARPA, made possible by Bob Kahn.
  </p>
</section>
</section>
</main>

<nav>
  <menu>
    <li><a href="#s0">Preamble</a></li>
  </menu>
</nav>

<footer>
  <h2>Attribution</h2>
  <p>
    <a href="https://creativecommons.org/licenses/by-sa/4.0/"><img
      src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png"></a> <br>
    Structure and Interpretation of Computer Programs by <a
    href="https://mitpress.mit.edu/sicp">Harold Abelson and Gerald Jay Sussman
    with Julie Sussman</a> is licensed under a <a
    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons
    Attribution-ShareAlike 4.0 International License</a> by the MIT Press.
    
  </p>
</footer>
</body>